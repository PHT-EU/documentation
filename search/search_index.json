{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview Documentation and User Guide for the Personal Health Train (PHT) an open source, container based secure distributed analysis platform. For more information about the PHT team, projects and collaborations you can also visit our website . Introduction The Personal Health Train (PHT) is a paradigm proposed within the GO:FAIR initiative as one solution for distributed analysis of medical data, enhancing their FAIRness. Rather than transferring data to a central analysis site, the analysis algorithm (wrapped in a \u2018train\u2019), travels between multiple sites (e.g., hospitals \u2013 so-called \u2018train stations\u2019) hosting the data in a secure fashion. The following overview shows all interactions between service components to execute a train iteratively over three stations with our PHT-TBI architecture. Mission Statement From machine learning (ML) healthcare can profit by \u2018learning\u2019 models which support clinical practice in treatment decision support systems (TDSS). To increase the robustness of an obtained model and produce meaningful results, generally the analysis outcome depends on the number of training samples and data quality. But meaningful data to improve predictions in medical research and healthcare is often distributed across multiple sites and is not easily accessible. This data contains highly sensitive patient information, may consist at each site different data formats and cannot be shared without explicit consent of the patient. Our goal is to make this data available for trains with stations to support privacy preserving distributed machine learning in healthcare with our open-source implementation of the PHT. Implementing trains as light-weight containers enables even complex data analysis workflows to travel between sites, for example, genomics pipelines or deep-learning algorithms \u2013 analytics methods that are not easily amenable to established distributed queries or simple statistics. Architecture Central Services RabbitMQ - Message broker for consuming and publishing commands & events between different services Harbor - Docker registry to manage (train-) images Vault - Secret storage to securely store sensitive information User Interface (UI) - Frontend application for proposal and train management, downloading of results and much more API - Backend application to manage resources and trigger commands & events through the message broker Train Manager - Microservice serving different components: Train Building - Build and distribute train images to a registry Train Routing - Move trains between projects & registries accordingly to the route of the train Result Extracting - Download, extract & serve encrypted results from the registry Local/Station Services Airflow - Open-Source-Tool to create and schedule workflows and enables persistent access to data, execution and monitoring of trains Keycloak - Identity and Access Management (IAM) to manage users and roles Desktop App - GUI to manage key pairs and decrypt results locally Security Security Protocol The following flow chart depicts the security protocol used for protecting participating stations against malicious code, as well as encrypting any stored results using envelope encryption. This ensures that only approved algorithms are executed and that only previously registered participants in an analysis can access the results. Languages JavaScript Wikipedia: JavaScript ( https://developer.mozilla.org/en/docs/Web/JavaScript ) often abbreviated JS, is a programming language that is one of the core technologies of the World Wide Web, alongside HTML and CSS. TypeScript Wikipedia: TypeScript ( https://www.typescriptlang.org/ ) is a programming language developed and maintained by Microsoft. It is a strict syntactical superset of JavaScript and adds optional static typing to the language. It is designed for the development of large applications and transpiles to JavaScript. Python Wikipedia: Python ( https://python.org ) is an interpreted high-level general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant indentation. Its language constructs as well as its object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.","title":"What is the PHT?"},{"location":"#overview","text":"Documentation and User Guide for the Personal Health Train (PHT) an open source, container based secure distributed analysis platform. For more information about the PHT team, projects and collaborations you can also visit our website .","title":"Overview"},{"location":"#introduction","text":"The Personal Health Train (PHT) is a paradigm proposed within the GO:FAIR initiative as one solution for distributed analysis of medical data, enhancing their FAIRness. Rather than transferring data to a central analysis site, the analysis algorithm (wrapped in a \u2018train\u2019), travels between multiple sites (e.g., hospitals \u2013 so-called \u2018train stations\u2019) hosting the data in a secure fashion. The following overview shows all interactions between service components to execute a train iteratively over three stations with our PHT-TBI architecture.","title":"Introduction"},{"location":"#mission-statement","text":"From machine learning (ML) healthcare can profit by \u2018learning\u2019 models which support clinical practice in treatment decision support systems (TDSS). To increase the robustness of an obtained model and produce meaningful results, generally the analysis outcome depends on the number of training samples and data quality. But meaningful data to improve predictions in medical research and healthcare is often distributed across multiple sites and is not easily accessible. This data contains highly sensitive patient information, may consist at each site different data formats and cannot be shared without explicit consent of the patient. Our goal is to make this data available for trains with stations to support privacy preserving distributed machine learning in healthcare with our open-source implementation of the PHT. Implementing trains as light-weight containers enables even complex data analysis workflows to travel between sites, for example, genomics pipelines or deep-learning algorithms \u2013 analytics methods that are not easily amenable to established distributed queries or simple statistics.","title":"Mission Statement"},{"location":"#architecture","text":"","title":"Architecture"},{"location":"#central-services","text":"RabbitMQ - Message broker for consuming and publishing commands & events between different services Harbor - Docker registry to manage (train-) images Vault - Secret storage to securely store sensitive information User Interface (UI) - Frontend application for proposal and train management, downloading of results and much more API - Backend application to manage resources and trigger commands & events through the message broker Train Manager - Microservice serving different components: Train Building - Build and distribute train images to a registry Train Routing - Move trains between projects & registries accordingly to the route of the train Result Extracting - Download, extract & serve encrypted results from the registry","title":"Central Services"},{"location":"#localstation-services","text":"Airflow - Open-Source-Tool to create and schedule workflows and enables persistent access to data, execution and monitoring of trains Keycloak - Identity and Access Management (IAM) to manage users and roles Desktop App - GUI to manage key pairs and decrypt results locally","title":"Local/Station Services"},{"location":"#security","text":"","title":"Security"},{"location":"#security-protocol","text":"The following flow chart depicts the security protocol used for protecting participating stations against malicious code, as well as encrypting any stored results using envelope encryption. This ensures that only approved algorithms are executed and that only previously registered participants in an analysis can access the results.","title":"Security Protocol"},{"location":"#languages","text":"","title":"Languages"},{"location":"#javascript","text":"Wikipedia: JavaScript ( https://developer.mozilla.org/en/docs/Web/JavaScript ) often abbreviated JS, is a programming language that is one of the core technologies of the World Wide Web, alongside HTML and CSS.","title":"JavaScript"},{"location":"#typescript","text":"Wikipedia: TypeScript ( https://www.typescriptlang.org/ ) is a programming language developed and maintained by Microsoft. It is a strict syntactical superset of JavaScript and adds optional static typing to the language. It is designed for the development of large applications and transpiles to JavaScript.","title":"TypeScript"},{"location":"#python","text":"Wikipedia: Python ( https://python.org ) is an interpreted high-level general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant indentation. Its language constructs as well as its object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.","title":"Python"},{"location":"components/","text":"Components Multiple git repositories contain the components of the PHT. These can be roughly separated into the following categories: * global * central * local/station All public repositories can be found on GitHub . Global Global components/services are neither used exclusive on central nor local/station side. Service Repository Programing Language Lead Train Container Library Train-Container-Library Python migraf Central Central components/services (Central UI, Train building, Train Routing, Result Extraction, API, etc.) are individual packages within one monorepo. Service Repository Programing Language Lead Central Central JavaScript/TypeScript tada5hi Local/Station Service Repository Programing Language Lead Station Station Python migraf Desktop App Desktop-App JavaScript/TypeScript tada5hi Third Party Services The PHT relies heavily on other great open-source projects. Not only as libraries but also as standalone components of our architecture. Central Harbor The container registry provided by the Harbor project is the central data/algorithm exchange platform of the PHT. Trains are defined as images which are distributed between the participants private harbor projects. Vault For securely storing sensitive user or train data as key-value pairs we utilize Vault by Hashicorp as secret storage for our central services. Local/Station Apache Airflow Apache Airflow is an open source, community developed platform to programmatically author, schedule and monitor workflows and the primary component of the station. FHIR To overcome local setup differences between stations, the PHT provides controlled and reliable access to different FHIR Servers. We support the IBM FHIR Server , Blaze and HAPI server. University hospital T\u00fcbingen is using the IBM FHIR server. Keycloak A user within the central user interface has always to be associated to a station. Each station can independently use different IAMs. We in T\u00fcbingen use Keycloak for our user management. Credits Icons used from flaticon and freepik","title":"Components"},{"location":"components/#components","text":"Multiple git repositories contain the components of the PHT. These can be roughly separated into the following categories: * global * central * local/station All public repositories can be found on GitHub .","title":"Components"},{"location":"components/#global","text":"Global components/services are neither used exclusive on central nor local/station side. Service Repository Programing Language Lead Train Container Library Train-Container-Library Python migraf","title":"Global"},{"location":"components/#central","text":"Central components/services (Central UI, Train building, Train Routing, Result Extraction, API, etc.) are individual packages within one monorepo. Service Repository Programing Language Lead Central Central JavaScript/TypeScript tada5hi","title":"Central"},{"location":"components/#localstation","text":"Service Repository Programing Language Lead Station Station Python migraf Desktop App Desktop-App JavaScript/TypeScript tada5hi","title":"Local/Station"},{"location":"components/#third-party-services","text":"The PHT relies heavily on other great open-source projects. Not only as libraries but also as standalone components of our architecture.","title":"Third Party Services"},{"location":"components/#central_1","text":"","title":"Central"},{"location":"components/#harbor","text":"The container registry provided by the Harbor project is the central data/algorithm exchange platform of the PHT. Trains are defined as images which are distributed between the participants private harbor projects.","title":"Harbor"},{"location":"components/#vault","text":"For securely storing sensitive user or train data as key-value pairs we utilize Vault by Hashicorp as secret storage for our central services.","title":"Vault"},{"location":"components/#localstation_1","text":"","title":"Local/Station"},{"location":"components/#apache-airflow","text":"Apache Airflow is an open source, community developed platform to programmatically author, schedule and monitor workflows and the primary component of the station.","title":"Apache Airflow"},{"location":"components/#fhir","text":"To overcome local setup differences between stations, the PHT provides controlled and reliable access to different FHIR Servers. We support the IBM FHIR Server , Blaze and HAPI server. University hospital T\u00fcbingen is using the IBM FHIR server.","title":"FHIR"},{"location":"components/#keycloak","text":"A user within the central user interface has always to be associated to a station. Each station can independently use different IAMs. We in T\u00fcbingen use Keycloak for our user management.","title":"Keycloak"},{"location":"components/#credits","text":"Icons used from flaticon and freepik","title":"Credits"},{"location":"fyi/","text":"For Your Information (FYI) Publications Info coming soon Join the Community Feel free to join our discord server here or follow us on github Meet the Team - Core (Developer-) Members Please visit our official website: https://personalhealthtrain.de/about-us/","title":"For Your Information (FYI)"},{"location":"fyi/#for-your-information-fyi","text":"","title":"For Your Information (FYI)"},{"location":"fyi/#publications","text":"Info coming soon","title":"Publications"},{"location":"fyi/#join-the-community","text":"Feel free to join our discord server here or follow us on github","title":"Join the Community"},{"location":"fyi/#meet-the-team-core-developer-members","text":"Please visit our official website: https://personalhealthtrain.de/about-us/","title":"Meet the Team - Core (Developer-) Members"},{"location":"glossar/","text":"Term Explanation IAM Identity and Access Management Paillier - key This is the key to a homomorphic encryption system to additionally secure the calculated data inside of a train PHT Personal Health Train Proposal A Proposal is an organizational unit in the PHT, which represents the collaboration between different participants in regard to a specific research or analysis project. It contains an initial risk assessment as well as a high level description of the requested data. Registry Service to distribute trains RSA - key This is the key to a homomorphic encryption system to secure the train from external influences Stations Hospitals hosting a station to provide trains controlled and secure access to patient data Trains Docker containers containing algorithm, train logic and software dependencies UI User Interface","title":"Glossar"},{"location":"cord_demo/cord_demo/","text":"PHT CORD Demo This section will provide explanations and examples for writing and executing CORD demo code and queries by using PHT meDIC. By using the demo account, we automatically accept and execute your analysis over three stations providing secure access to synthetic CORD demo data in FHIR. Demo credentials for PHT demo : username demo_user and password cord_pht_demo . With this user you can use all functionalities and take a look at our admin area. Don't worry and play around, you cannot break something and the system resets itself. Running CORD demo trains We suggest to you to follow these steps: Download and install our Offline Tool. Load the private keys. Train submission: Define your FHIR query to be executed (see section below). Define your analysis (see section below). Submit your code (see section below). Run the train. Decrypt results. Step 1 - Preliminaries Download and install the Offline Tool from our releases page . The demo user has predefined keys . Please download those. Login to our PHT demo page with username demo_user and password cord_pht_demo . Step 2 - Offline Tool and key loading Get familiar with its functionalities. Additional information can be found in the offline tool documentation . You need to download and use the keys in order to decrypt the analysis results. Go to the Security Values section of the tool and load the previous downloaded demo-start123_sk.pem private key. You need to enter the password of the private key: start123 . Now you can continue with the train submission - you will need to sign your submitted code and query with your private key. Step 3 - Train submission For this CORD PHT demo we recommend using or customizing an example train. Please clone this repository if you want to use our example trains. Now you need to decide if you want to run a Python or R analysis. By writing the analysis code, you specify the data access, we recommend using FHIR. Step 3.1 - FHIR queries Our self implemented train-library not only includes security but also standardised FHIR query execution and access and currently supports the following servers: IBM, Hapi and Blaze. In this demo we use Blaze FHIR servers. Read this section for details regarding FHIR queries: FHIR query documentation or continue with the train submission. Step 3.2 - Write your analysis code You can write your analysis code in any IDE. We suggest to use PyCharm for Python and RStudio for R code. The following examples will be executed at each station. Please get familiar with the following Python or R code: R demo trains code is documented here: R CORD documentation Python demo trains code is documented here: Python CORD documentation Step 3.3 - Code submission Upload your analysis code within the UI and select the entrypoint (script to be executed at stations if multiple files are submitted). The hash of the uploaded files and query needs to be signed by using the Offline Tool with your private key. The next steps guide you through the general submission process, exemplified by the submission of R demo train 2 . Login to the UI Create a new train. Select the proposal based on your desired programming language. Keep the default Demo master image of the train unchanged, if you submit provided example code. Specify the stations to be executed at and select depending on your programming language the master image. Upload the algorithm and select the entrypoint of the train. Specify the query Sign the hash with the local Offline Tool: Documentation Step 4 - Train running You need to build and run the train before you can download the results. Start the building process of the train. Please manually reload the page within the browser after 30-40 seconds. Then you will be able to start the execution at the stations. After a few minutes, results are available. Please reload the page manually again. A soon released feature will display the progress of the train in the Stations overview with a random station numbering. The user will also be able to see log files of the train. Step 5 - result download and decryption After a few minutes your train results can be downloaded. The files are automatically encrypted and need to be decrypted with the Offline Tool. Please follow these steps: Download results Unzip the downloaded train results locally Result decryption: Start the Offline Tool Go to the \"Model\" section Load your private key Open the unzipped result directory \"pht_results\" Load the \"train_config.json\"-file of your train Select the files to decrypt (the selected ones appear in the box on the right) Decrypt the files by pressing the \"Decrypt selected models\" button View, process and store the results locally on your computer. You can directly access them with the \"Show decrypted files\" button. More information regarding result decryption can be read here . The decrypted files can be accessed from your explorer or finder locally. FAQ Train not updating Question: My train is not updated in the UI, what can I do? Answer Most likely your code or query has caused an error during execution. We work on extending this version to provide you with log files from the execution. Is this the PHT? Question: Is this the Personal Health Train? Answer This is the implementation of the PHT from T\u00fcbingen University (PHT-meDIC). Many other versions exist. Any difference in the demo? Question: Is the PHT-meDIC as it would operate on real patient data? Answer All services are interacting in this demo, as it would be on real data. But there is a major difference: any train will be approved and executed. There is no one to validate, if something malicious is ongoing. In case you saved all patient data as fake results in the train, you did not break the system nor hacked the architecture. We allowed you and automatically executed your train to do so.","title":"PHT CORD Demo"},{"location":"cord_demo/cord_demo/#pht-cord-demo","text":"This section will provide explanations and examples for writing and executing CORD demo code and queries by using PHT meDIC. By using the demo account, we automatically accept and execute your analysis over three stations providing secure access to synthetic CORD demo data in FHIR. Demo credentials for PHT demo : username demo_user and password cord_pht_demo . With this user you can use all functionalities and take a look at our admin area. Don't worry and play around, you cannot break something and the system resets itself.","title":"PHT CORD Demo"},{"location":"cord_demo/cord_demo/#running-cord-demo-trains","text":"We suggest to you to follow these steps: Download and install our Offline Tool. Load the private keys. Train submission: Define your FHIR query to be executed (see section below). Define your analysis (see section below). Submit your code (see section below). Run the train. Decrypt results.","title":"Running CORD demo trains"},{"location":"cord_demo/cord_demo/#step-1-preliminaries","text":"Download and install the Offline Tool from our releases page . The demo user has predefined keys . Please download those. Login to our PHT demo page with username demo_user and password cord_pht_demo .","title":"Step 1 - Preliminaries"},{"location":"cord_demo/cord_demo/#step-2-offline-tool-and-key-loading","text":"Get familiar with its functionalities. Additional information can be found in the offline tool documentation . You need to download and use the keys in order to decrypt the analysis results. Go to the Security Values section of the tool and load the previous downloaded demo-start123_sk.pem private key. You need to enter the password of the private key: start123 . Now you can continue with the train submission - you will need to sign your submitted code and query with your private key.","title":"Step 2 - Offline Tool and key loading"},{"location":"cord_demo/cord_demo/#step-3-train-submission","text":"For this CORD PHT demo we recommend using or customizing an example train. Please clone this repository if you want to use our example trains. Now you need to decide if you want to run a Python or R analysis. By writing the analysis code, you specify the data access, we recommend using FHIR.","title":"Step 3 - Train submission"},{"location":"cord_demo/cord_demo/#step-31-fhir-queries","text":"Our self implemented train-library not only includes security but also standardised FHIR query execution and access and currently supports the following servers: IBM, Hapi and Blaze. In this demo we use Blaze FHIR servers. Read this section for details regarding FHIR queries: FHIR query documentation or continue with the train submission.","title":"Step 3.1 - FHIR queries"},{"location":"cord_demo/cord_demo/#step-32-write-your-analysis-code","text":"You can write your analysis code in any IDE. We suggest to use PyCharm for Python and RStudio for R code. The following examples will be executed at each station. Please get familiar with the following Python or R code: R demo trains code is documented here: R CORD documentation Python demo trains code is documented here: Python CORD documentation","title":"Step 3.2 - Write your analysis code"},{"location":"cord_demo/cord_demo/#step-33-code-submission","text":"Upload your analysis code within the UI and select the entrypoint (script to be executed at stations if multiple files are submitted). The hash of the uploaded files and query needs to be signed by using the Offline Tool with your private key. The next steps guide you through the general submission process, exemplified by the submission of R demo train 2 . Login to the UI Create a new train. Select the proposal based on your desired programming language. Keep the default Demo master image of the train unchanged, if you submit provided example code. Specify the stations to be executed at and select depending on your programming language the master image. Upload the algorithm and select the entrypoint of the train. Specify the query Sign the hash with the local Offline Tool: Documentation","title":"Step 3.3 - Code submission"},{"location":"cord_demo/cord_demo/#step-4-train-running","text":"You need to build and run the train before you can download the results. Start the building process of the train. Please manually reload the page within the browser after 30-40 seconds. Then you will be able to start the execution at the stations. After a few minutes, results are available. Please reload the page manually again. A soon released feature will display the progress of the train in the Stations overview with a random station numbering. The user will also be able to see log files of the train.","title":"Step 4 - Train running"},{"location":"cord_demo/cord_demo/#step-5-result-download-and-decryption","text":"After a few minutes your train results can be downloaded. The files are automatically encrypted and need to be decrypted with the Offline Tool. Please follow these steps: Download results Unzip the downloaded train results locally Result decryption: Start the Offline Tool Go to the \"Model\" section Load your private key Open the unzipped result directory \"pht_results\" Load the \"train_config.json\"-file of your train Select the files to decrypt (the selected ones appear in the box on the right) Decrypt the files by pressing the \"Decrypt selected models\" button View, process and store the results locally on your computer. You can directly access them with the \"Show decrypted files\" button. More information regarding result decryption can be read here . The decrypted files can be accessed from your explorer or finder locally.","title":"Step 5 - result download and decryption"},{"location":"cord_demo/cord_demo/#faq","text":"","title":"FAQ"},{"location":"cord_demo/cord_demo/#train-not-updating","text":"Question: My train is not updated in the UI, what can I do? Answer Most likely your code or query has caused an error during execution. We work on extending this version to provide you with log files from the execution.","title":"Train not updating"},{"location":"cord_demo/cord_demo/#is-this-the-pht","text":"Question: Is this the Personal Health Train? Answer This is the implementation of the PHT from T\u00fcbingen University (PHT-meDIC). Many other versions exist.","title":"Is this the PHT?"},{"location":"cord_demo/cord_demo/#any-difference-in-the-demo","text":"Question: Is the PHT-meDIC as it would operate on real patient data? Answer All services are interacting in this demo, as it would be on real data. But there is a major difference: any train will be approved and executed. There is no one to validate, if something malicious is ongoing. In case you saved all patient data as fake results in the train, you did not break the system nor hacked the architecture. We allowed you and automatically executed your train to do so.","title":"Any difference in the demo?"},{"location":"cord_demo/cord_fhir/","text":"CORD Demo FHIR You need to specify two minimal things for our self developed FHIR client in our train-library: The Resource to access (e.g. Patient or Condition ). The format and name the file should be provided to the train (accessed in the algorithm). To see what kind of queries are possible read the following general documentation of FHIR search queries. Minimal FHIR queries The train library requires the following minimal specifications: { \"query\" : \"/Patient?\" , \"data\" : { \"output_format\" : \"xml\" , \"filename\" : \"patients.xml\" } } This minimal query will load all CORD demo data from each station. FHIR queries with conditions If you want to query specific gender or ages extend your query: { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"birthdate\" , \"condition\" : \"gt1960\" }, { \"variable\" : \"gender\" , \"condition\" : \"female\" } ] }, \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"query_results.json\" } } This query will now only return female subjects, born in a year greater than 1960 for the Python train example. The R demo trains require as input data: { \"data\" : { \"output_format\" : \"xml\" , \"filename\" : \"patients.xml\" } } FHIR queries using different resources and conditions More advanced queries including searching multiple resources are demonstrated: { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"gender\" , \"condition\" : \"male\" }, { \"variable\" : \"birthdate\" , \"condition\" : \"gt1980-08-12\" } ], \"has\" : [ { \"resource\" : \"Condition\" , \"property\" : \"code\" , \"params\" : [ \"E70.0\" , \"I20.0\" ] } ] }, \"data\" : { \"output_format\" : \"xml\" , \"filename\" : \"patients.xml\" } } Now only male subjects born in a year greater than 1980 that have a condition related to PKU and unstable angina pectoris will be returned. Our PHT FHIR Client is part of our train-container-library .","title":"CORD Demo FHIR"},{"location":"cord_demo/cord_fhir/#cord-demo-fhir","text":"You need to specify two minimal things for our self developed FHIR client in our train-library: The Resource to access (e.g. Patient or Condition ). The format and name the file should be provided to the train (accessed in the algorithm). To see what kind of queries are possible read the following general documentation of FHIR search queries.","title":"CORD Demo FHIR"},{"location":"cord_demo/cord_fhir/#minimal-fhir-queries","text":"The train library requires the following minimal specifications: { \"query\" : \"/Patient?\" , \"data\" : { \"output_format\" : \"xml\" , \"filename\" : \"patients.xml\" } } This minimal query will load all CORD demo data from each station.","title":"Minimal FHIR queries"},{"location":"cord_demo/cord_fhir/#fhir-queries-with-conditions","text":"If you want to query specific gender or ages extend your query: { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"birthdate\" , \"condition\" : \"gt1960\" }, { \"variable\" : \"gender\" , \"condition\" : \"female\" } ] }, \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"query_results.json\" } } This query will now only return female subjects, born in a year greater than 1960 for the Python train example. The R demo trains require as input data: { \"data\" : { \"output_format\" : \"xml\" , \"filename\" : \"patients.xml\" } }","title":"FHIR queries with conditions"},{"location":"cord_demo/cord_fhir/#fhir-queries-using-different-resources-and-conditions","text":"More advanced queries including searching multiple resources are demonstrated: { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"gender\" , \"condition\" : \"male\" }, { \"variable\" : \"birthdate\" , \"condition\" : \"gt1980-08-12\" } ], \"has\" : [ { \"resource\" : \"Condition\" , \"property\" : \"code\" , \"params\" : [ \"E70.0\" , \"I20.0\" ] } ] }, \"data\" : { \"output_format\" : \"xml\" , \"filename\" : \"patients.xml\" } } Now only male subjects born in a year greater than 1980 that have a condition related to PKU and unstable angina pectoris will be returned. Our PHT FHIR Client is part of our train-container-library .","title":"FHIR queries using different resources and conditions"},{"location":"cord_demo/cord_python/","text":"Python code This code can be downloaded from this repository . Demo Train 1 The following query filters at each station for female patients born in a year greater than 1960. { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"birthdate\" , \"condition\" : \"gt1960\" }, { \"variable\" : \"gender\" , \"condition\" : \"female\" } ] }, \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"query_results.json\" } } The by the station loaded and provided query_results.json file will be processed and counts the occurrences of values. import os import json import pandas as pd import pathlib from dotenv import load_dotenv , find_dotenv DATA_PATH = os . getenv ( \"TRAIN_DATA_PATH\" ) FHIR_PATH = \"/opt/train_data/cord_results.json\" RESULT_PATH = '/opt/pht_results/results.txt' def load_if_exists ( model_path : str ): \"\"\" Load previous computed results, if available :param model_path: Path of models or results to load :return: model \"\"\" p = pathlib . Path ( model_path ) if pathlib . Path . is_file ( p ): print ( \"Loading previous results\" ) with open ( p , \"r\" ) as model_file : model = json . load ( model_file ) return model else : return None def save_results ( results , result_path ): \"\"\" Create (if doesnt exist) a result directory and store the analysis results within :param results: Result content :param result_path: Path of results file :return: store results as pickle file \"\"\" dirPath = '/opt/train_results' try : # Create target Directory os . mkdir ( dirPath ) print ( \"Directory \" , dirPath , \" Created (usually done by TB)\" ) except FileExistsError : print ( \"Directory \" , dirPath , \" already exists (done by TB)\" ) p = pathlib . Path ( result_path ) with open ( p , 'w' ) as results_file : json . dump ( results , results_file ) print ( \"Saved files\" ) def parse_fhir_response () -> pd . DataFrame : \"\"\" Load and parse provided FHIR resources to a pandas dataframe :return: \"\"\" with open ( FHIR_PATH , \"r\" ) as f : results = json . load ( f ) parsed_resources = [] for patient in results [ \"entry\" ]: resource = patient [ \"resource\" ] parsed_resources . append ( parse_resource ( resource )) df = pd . DataFrame ( parsed_resources ) return df def parse_resource ( resource ): \"\"\" Parse a FHIR resource returned from a FHIR server in a desired format :param resource: :return: dictionary of parsed resource \"\"\" # TODO change here to specify required resources sequence_dict = { \"givenName\" : resource [ 'name' ][ 0 ][ 'given' ], \"familyName\" : resource [ 'name' ][ 0 ][ 'family' ], \"birthDate\" : resource [ \"birthDate\" ], \"gender\" : resource [ \"gender\" ] } return sequence_dict def occurence_data ( pat_df , column ): \"\"\" Return value counts of given dataframe columns :param pat_df: Dataframe :param column: Column included in Dataframe :return: Series of value occurences \"\"\" return pat_df [ column ] . value_counts () if __name__ == '__main__' : \"\"\" Main analysis function of the train - the CORD minimal demo, requires only result files and no models :return: \"\"\" load_dotenv ( find_dotenv ()) # parse the FHIR response and load previous results (if available) pat_df = parse_fhir_response () # Try to load previous results, if no exist create dictionary and print results before execution of analysis try : results = load_if_exists ( RESULT_PATH ) except FileNotFoundError : print ( \"No file available\" ) if results is None : results = { 'analysis' : {}, 'discovery' : {}} print ( \"Previous results: {} \" . format ( results )) # Write analysis code here # demo function to count occurence of specified variables occ = occurence_data ( pat_df , 'gender' ) results [ 'analysis' ][ 'analysis_exec_' + str ( len ( results [ 'analysis' ]) + 1 )] = str ( occ ) # print updated results print ( \"Updated results: {} \" . format ( results )) save_results ( results , RESULT_PATH ) Demo Train 2 An advantage to use Python is the use of our secure count possibilities, based paillier cryptosystem. Doing such, you can add, multiply or subtract an encrypted integer number from another encrypted number. This way, you can e.g. count the total number of certain conditions matching within a cohort, without revealing the input value from any site. import os import json import pandas as pd import pathlib from dotenv import load_dotenv , find_dotenv from train_lib.security.HomomorphicAddition import secure_addition DATA_PATH = os . getenv ( \"TRAIN_DATA_PATH\" ) FHIR_PATH = \"/opt/train_data/cord_results.json\" RESULT_PATH = '/opt/pht_results/results.txt' def load_if_exists ( model_path : str ): \"\"\" Load previous computed results, if available :param model_path: Path of models or results to load :return: model \"\"\" p = pathlib . Path ( model_path ) if pathlib . Path . is_file ( p ): print ( \"Loading previous results\" ) with open ( p , \"r\" ) as model_file : model = json . load ( model_file ) return model else : return None def save_results ( results , result_path ): \"\"\" Create (if doesnt exist) a result directory and store the analysis results within :param results: Result content :param result_path: Path of results file :return: store results as pickle file \"\"\" dirPath = '/opt/pht_results' try : # Create target Directory os . mkdir ( dirPath ) print ( \"Directory \" , dirPath , \" Created (usually done by TB)\" ) except FileExistsError : print ( \"Directory \" , dirPath , \" already exists (done by TB)\" ) p = pathlib . Path ( result_path ) with open ( p , 'w' ) as results_file : return json . dump ( results , results_file ) def parse_fhir_response () -> pd . DataFrame : \"\"\" Load and parse provided FHIR resources to a pandas dataframe :return: \"\"\" with open ( FHIR_PATH , \"r\" ) as f : results = json . load ( f ) parsed_resources = [] for patient in results [ \"entry\" ]: resource = patient [ \"resource\" ] parsed_resources . append ( parse_resource ( resource )) df = pd . DataFrame ( parsed_resources ) return df def parse_resource ( resource ): \"\"\" Parse a FHIR resource returned from a FHIR server in a desired format :param resource: :return: dictionary of parsed resource \"\"\" sequence_dict = { \"givenName\" : resource [ 'name' ][ 0 ][ 'given' ], \"familyName\" : resource [ 'name' ][ 0 ][ 'family' ], \"birthDate\" : resource [ \"birthDate\" ], \"gender\" : resource [ \"gender\" ] } return sequence_dict def get_user_pk (): try : with open ( '/opt/train_config.json' , 'r' ) as train_conf : conf = json . load ( train_conf ) return conf [ 'user_secure_add_pk' ] except Exception : return { 'user_secure_add_pk' : None } def paillier_addition ( prev_result , local_result , number_to_add ): try : curr_result = prev_result [ 'analysis' ][ number_to_add ] print ( \"Previous secure addition value from {} {} \" . format ( number_to_add , curr_result )) except KeyError : print ( \"Previous secure addition from {} empty\" . format ( number_to_add )) curr_result = None default_user_he_pk_key = 318693975235417112059593426070243914461 return secure_addition ( local_result , curr_result , int ( default_user_he_pk_key )) if __name__ == '__main__' : \"\"\" Main analysis function of the train - the CORD minimal demo for secure calculation of average age :return: \"\"\" load_dotenv ( find_dotenv ()) # parse the FHIR response and load previous results (if available) pat_df = parse_fhir_response () # Try to load previous results, if no exist create dictionary and print results before execution of analysis try : results = load_if_exists ( RESULT_PATH ) except FileNotFoundError : print ( \"No file available\" ) if results is None : results = { 'analysis' : {}, 'discovery' : {}} print ( \"Previous results: {} \" . format ( results )) # Write analysis code here # demo function to calculate average age secure now = pd . Timestamp ( 'now' ) pat_df [ 'birthDate' ] = pd . to_datetime ( pat_df [ 'birthDate' ]) pat_df [ 'age' ] = ( now - pat_df [ 'birthDate' ]) . astype ( '<m8[Y]' ) sum_age = int ( pat_df [ 'age' ] . sum ()) sum_pat = int ( pat_df . shape [ 0 ]) secure_age = paillier_addition ( results , sum_age , 'secure_age' ) secure_pat = paillier_addition ( results , sum_pat , 'secure_pat' ) results [ 'analysis' ][ 'secure_age' ] = secure_age results [ 'analysis' ][ 'secure_pat' ] = secure_pat # print updated results print ( \"Updated results: {} \" . format ( results )) save_results ( results , RESULT_PATH ) This train uses the same FHIR query and the example is here . To decrypt and understand the results, please read the Offline Tool documentation .","title":"Python code"},{"location":"cord_demo/cord_python/#python-code","text":"This code can be downloaded from this repository .","title":"Python code"},{"location":"cord_demo/cord_python/#demo-train-1","text":"The following query filters at each station for female patients born in a year greater than 1960. { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"birthdate\" , \"condition\" : \"gt1960\" }, { \"variable\" : \"gender\" , \"condition\" : \"female\" } ] }, \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"query_results.json\" } } The by the station loaded and provided query_results.json file will be processed and counts the occurrences of values. import os import json import pandas as pd import pathlib from dotenv import load_dotenv , find_dotenv DATA_PATH = os . getenv ( \"TRAIN_DATA_PATH\" ) FHIR_PATH = \"/opt/train_data/cord_results.json\" RESULT_PATH = '/opt/pht_results/results.txt' def load_if_exists ( model_path : str ): \"\"\" Load previous computed results, if available :param model_path: Path of models or results to load :return: model \"\"\" p = pathlib . Path ( model_path ) if pathlib . Path . is_file ( p ): print ( \"Loading previous results\" ) with open ( p , \"r\" ) as model_file : model = json . load ( model_file ) return model else : return None def save_results ( results , result_path ): \"\"\" Create (if doesnt exist) a result directory and store the analysis results within :param results: Result content :param result_path: Path of results file :return: store results as pickle file \"\"\" dirPath = '/opt/train_results' try : # Create target Directory os . mkdir ( dirPath ) print ( \"Directory \" , dirPath , \" Created (usually done by TB)\" ) except FileExistsError : print ( \"Directory \" , dirPath , \" already exists (done by TB)\" ) p = pathlib . Path ( result_path ) with open ( p , 'w' ) as results_file : json . dump ( results , results_file ) print ( \"Saved files\" ) def parse_fhir_response () -> pd . DataFrame : \"\"\" Load and parse provided FHIR resources to a pandas dataframe :return: \"\"\" with open ( FHIR_PATH , \"r\" ) as f : results = json . load ( f ) parsed_resources = [] for patient in results [ \"entry\" ]: resource = patient [ \"resource\" ] parsed_resources . append ( parse_resource ( resource )) df = pd . DataFrame ( parsed_resources ) return df def parse_resource ( resource ): \"\"\" Parse a FHIR resource returned from a FHIR server in a desired format :param resource: :return: dictionary of parsed resource \"\"\" # TODO change here to specify required resources sequence_dict = { \"givenName\" : resource [ 'name' ][ 0 ][ 'given' ], \"familyName\" : resource [ 'name' ][ 0 ][ 'family' ], \"birthDate\" : resource [ \"birthDate\" ], \"gender\" : resource [ \"gender\" ] } return sequence_dict def occurence_data ( pat_df , column ): \"\"\" Return value counts of given dataframe columns :param pat_df: Dataframe :param column: Column included in Dataframe :return: Series of value occurences \"\"\" return pat_df [ column ] . value_counts () if __name__ == '__main__' : \"\"\" Main analysis function of the train - the CORD minimal demo, requires only result files and no models :return: \"\"\" load_dotenv ( find_dotenv ()) # parse the FHIR response and load previous results (if available) pat_df = parse_fhir_response () # Try to load previous results, if no exist create dictionary and print results before execution of analysis try : results = load_if_exists ( RESULT_PATH ) except FileNotFoundError : print ( \"No file available\" ) if results is None : results = { 'analysis' : {}, 'discovery' : {}} print ( \"Previous results: {} \" . format ( results )) # Write analysis code here # demo function to count occurence of specified variables occ = occurence_data ( pat_df , 'gender' ) results [ 'analysis' ][ 'analysis_exec_' + str ( len ( results [ 'analysis' ]) + 1 )] = str ( occ ) # print updated results print ( \"Updated results: {} \" . format ( results )) save_results ( results , RESULT_PATH )","title":"Demo Train 1"},{"location":"cord_demo/cord_python/#demo-train-2","text":"An advantage to use Python is the use of our secure count possibilities, based paillier cryptosystem. Doing such, you can add, multiply or subtract an encrypted integer number from another encrypted number. This way, you can e.g. count the total number of certain conditions matching within a cohort, without revealing the input value from any site. import os import json import pandas as pd import pathlib from dotenv import load_dotenv , find_dotenv from train_lib.security.HomomorphicAddition import secure_addition DATA_PATH = os . getenv ( \"TRAIN_DATA_PATH\" ) FHIR_PATH = \"/opt/train_data/cord_results.json\" RESULT_PATH = '/opt/pht_results/results.txt' def load_if_exists ( model_path : str ): \"\"\" Load previous computed results, if available :param model_path: Path of models or results to load :return: model \"\"\" p = pathlib . Path ( model_path ) if pathlib . Path . is_file ( p ): print ( \"Loading previous results\" ) with open ( p , \"r\" ) as model_file : model = json . load ( model_file ) return model else : return None def save_results ( results , result_path ): \"\"\" Create (if doesnt exist) a result directory and store the analysis results within :param results: Result content :param result_path: Path of results file :return: store results as pickle file \"\"\" dirPath = '/opt/pht_results' try : # Create target Directory os . mkdir ( dirPath ) print ( \"Directory \" , dirPath , \" Created (usually done by TB)\" ) except FileExistsError : print ( \"Directory \" , dirPath , \" already exists (done by TB)\" ) p = pathlib . Path ( result_path ) with open ( p , 'w' ) as results_file : return json . dump ( results , results_file ) def parse_fhir_response () -> pd . DataFrame : \"\"\" Load and parse provided FHIR resources to a pandas dataframe :return: \"\"\" with open ( FHIR_PATH , \"r\" ) as f : results = json . load ( f ) parsed_resources = [] for patient in results [ \"entry\" ]: resource = patient [ \"resource\" ] parsed_resources . append ( parse_resource ( resource )) df = pd . DataFrame ( parsed_resources ) return df def parse_resource ( resource ): \"\"\" Parse a FHIR resource returned from a FHIR server in a desired format :param resource: :return: dictionary of parsed resource \"\"\" sequence_dict = { \"givenName\" : resource [ 'name' ][ 0 ][ 'given' ], \"familyName\" : resource [ 'name' ][ 0 ][ 'family' ], \"birthDate\" : resource [ \"birthDate\" ], \"gender\" : resource [ \"gender\" ] } return sequence_dict def get_user_pk (): try : with open ( '/opt/train_config.json' , 'r' ) as train_conf : conf = json . load ( train_conf ) return conf [ 'user_secure_add_pk' ] except Exception : return { 'user_secure_add_pk' : None } def paillier_addition ( prev_result , local_result , number_to_add ): try : curr_result = prev_result [ 'analysis' ][ number_to_add ] print ( \"Previous secure addition value from {} {} \" . format ( number_to_add , curr_result )) except KeyError : print ( \"Previous secure addition from {} empty\" . format ( number_to_add )) curr_result = None default_user_he_pk_key = 318693975235417112059593426070243914461 return secure_addition ( local_result , curr_result , int ( default_user_he_pk_key )) if __name__ == '__main__' : \"\"\" Main analysis function of the train - the CORD minimal demo for secure calculation of average age :return: \"\"\" load_dotenv ( find_dotenv ()) # parse the FHIR response and load previous results (if available) pat_df = parse_fhir_response () # Try to load previous results, if no exist create dictionary and print results before execution of analysis try : results = load_if_exists ( RESULT_PATH ) except FileNotFoundError : print ( \"No file available\" ) if results is None : results = { 'analysis' : {}, 'discovery' : {}} print ( \"Previous results: {} \" . format ( results )) # Write analysis code here # demo function to calculate average age secure now = pd . Timestamp ( 'now' ) pat_df [ 'birthDate' ] = pd . to_datetime ( pat_df [ 'birthDate' ]) pat_df [ 'age' ] = ( now - pat_df [ 'birthDate' ]) . astype ( '<m8[Y]' ) sum_age = int ( pat_df [ 'age' ] . sum ()) sum_pat = int ( pat_df . shape [ 0 ]) secure_age = paillier_addition ( results , sum_age , 'secure_age' ) secure_pat = paillier_addition ( results , sum_pat , 'secure_pat' ) results [ 'analysis' ][ 'secure_age' ] = secure_age results [ 'analysis' ][ 'secure_pat' ] = secure_pat # print updated results print ( \"Updated results: {} \" . format ( results )) save_results ( results , RESULT_PATH ) This train uses the same FHIR query and the example is here . To decrypt and understand the results, please read the Offline Tool documentation .","title":"Demo Train 2"},{"location":"cord_demo/cord_r/","text":"R code You can find this example train within our R cord-demo repository Demo Train 1 This train uses the provided csv input file. You don't need to specify a FHIR query. Demo Train 2 The following two demo trains use the FHIRCracker to load the FHIR xml-bundles. This train creates an age distribution plot based on FHIR input data. The corresponding query is: { \"query\" : { \"resource\" : \"Patient\" }, \"data\" : { \"output_format\" : \"xml\" , \"filename\" : \"patients.xml\" } } You can extend or modify the query however you like. Demo Train 3 This train creates a histogram based on a complex FHIR query and creates a barplot of the counts. { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"gender\" , \"condition\" : \"male\" }, { \"variable\" : \"birthdate\" , \"condition\" : \"gt1980-08-12\" } ], \"has\" : [ { \"resource\" : \"Condition\" , \"property\" : \"code\" , \"params\" : [ \"E70.0\" , \"I20.0\" ] } ] }, \"data\" : { \"output_format\" : \"xml\" , \"filename\" : \"patients.xml\" } } You can find more R demo trains within our cord-demo repository Credits These example trains are based on the Projektathon4 repository","title":"Cord r"},{"location":"cord_demo/cord_r/#r-code","text":"You can find this example train within our R cord-demo repository","title":"R code"},{"location":"cord_demo/cord_r/#demo-train-1","text":"This train uses the provided csv input file. You don't need to specify a FHIR query.","title":"Demo Train 1"},{"location":"cord_demo/cord_r/#demo-train-2","text":"The following two demo trains use the FHIRCracker to load the FHIR xml-bundles. This train creates an age distribution plot based on FHIR input data. The corresponding query is: { \"query\" : { \"resource\" : \"Patient\" }, \"data\" : { \"output_format\" : \"xml\" , \"filename\" : \"patients.xml\" } } You can extend or modify the query however you like.","title":"Demo Train 2"},{"location":"cord_demo/cord_r/#demo-train-3","text":"This train creates a histogram based on a complex FHIR query and creates a barplot of the counts. { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"gender\" , \"condition\" : \"male\" }, { \"variable\" : \"birthdate\" , \"condition\" : \"gt1980-08-12\" } ], \"has\" : [ { \"resource\" : \"Condition\" , \"property\" : \"code\" , \"params\" : [ \"E70.0\" , \"I20.0\" ] } ] }, \"data\" : { \"output_format\" : \"xml\" , \"filename\" : \"patients.xml\" } } You can find more R demo trains within our cord-demo repository","title":"Demo Train 3"},{"location":"cord_demo/cord_r/#credits","text":"These example trains are based on the Projektathon4 repository","title":"Credits"},{"location":"station_guide/central_ui/","text":"Station settings In order to manage the stations settings the user needs to be assigned the Station Authority role. Warning When changing the settings of your station in the central UI you need to restart your local station. Add a realm In order to set a OIDC provider and manage your stations you need to get an organization. Please contact us, such we can provide you a realm in which you can manage all your stations, users and identity providers. Configuring an OIDC provider To allow each participant to control their own distribution of roles, the central UI allows the user to configure an OIDC provider which can be used to authenticate users associated with their realm. OIDC providers can be configured in the admin panel of the central UI under Auth -> Realms in the providers tab. Clicking on the Add button on the left will allow you to configure a new OIDC provider. Keycloak settings Any OpenID-provider can be configured to be selected in the login screen to authenticate users belonging to your realm. If you dont know how to set up a client in Keycloak, follow the steps below configuration. The following settings are used in the User Interface with Keycloak as identity provider: Name: <Display name in UI> Client-ID: <name of client specified in keycloak> Client Secret: <secret of client if set to confidential> Token Host: <URL to realm> (e.g. https://DOMAIN.de/auth/realms/PHT_DEV/) Path: protocol/openid-connect/token Authorization Host: Auto from Token Path: protocol/openid-connect/auth Create a Realm in Keycloak Create a realm - in this example: PHT_DEV Create a new client within this realm - in this example: pht-staging Set the access type to confidential and a root URL and the valid redirect URIs Copy your client secret and use it for the configuration in the UI The following two roles must be created in the identity provider Registering/Updating a public key Within the admin area (top left, next to Home), you need to select Auth -> Realms within the left navigation. You can see a list of stations. Choose the station you want and click on the blue \"List\"-Symbol. In Station the public key can be entered into the field PublicKey . Updating the Station ID Follow the steps 1 and 2 of \"Registering/Updating a public key\" On the same page you can find SecureID , which you can adapt. Setting/Updating harbor username and password Within the admin area (top left), you need select Realms within the left navigation. Select the Station you want to edit In Harbor the credentials, project name and path can be modified - webhooks for API communication can be tested. Review Before accepting a proposal or a train the requested data and the code contained in a train need to be reviewed. While removing network access and the built-in security features should be sufficient to prevent the transfer of data, the code still needs to be reviewed to prevent any unwanted behaviour. Proposal Proposals are the top level organizational unit of the PHT system. Proposals describe the goal of an analysis, the requested data and an estimation of the potential risk of participation. When the description of the proposal meets the local requirements of your station, a user with the role of Station Authority can accept the proposal, otherwise the proposal is rejected (optionally with comments for improvement). Joining a proposal means that users of other stations also joined in the proposal can select your station as a participant in the trains they create for this proposal. Train Trains contain analysis code that will be executed on the data requested in the proposal. The code is user submitted, so while the security protocol prevents the transfer of any unencrypted data via docker images and restricted network access, prevents direct transfer of any data, the code still needs to be reviewed in order to prevent any kind of malicious behaviour.","title":"Central UI"},{"location":"station_guide/central_ui/#station-settings","text":"In order to manage the stations settings the user needs to be assigned the Station Authority role. Warning When changing the settings of your station in the central UI you need to restart your local station.","title":"Station settings"},{"location":"station_guide/central_ui/#add-a-realm","text":"In order to set a OIDC provider and manage your stations you need to get an organization. Please contact us, such we can provide you a realm in which you can manage all your stations, users and identity providers.","title":"Add a realm"},{"location":"station_guide/central_ui/#configuring-an-oidc-provider","text":"To allow each participant to control their own distribution of roles, the central UI allows the user to configure an OIDC provider which can be used to authenticate users associated with their realm. OIDC providers can be configured in the admin panel of the central UI under Auth -> Realms in the providers tab. Clicking on the Add button on the left will allow you to configure a new OIDC provider.","title":"Configuring an OIDC provider"},{"location":"station_guide/central_ui/#keycloak-settings","text":"Any OpenID-provider can be configured to be selected in the login screen to authenticate users belonging to your realm. If you dont know how to set up a client in Keycloak, follow the steps below configuration. The following settings are used in the User Interface with Keycloak as identity provider: Name: <Display name in UI> Client-ID: <name of client specified in keycloak> Client Secret: <secret of client if set to confidential> Token Host: <URL to realm> (e.g. https://DOMAIN.de/auth/realms/PHT_DEV/) Path: protocol/openid-connect/token Authorization Host: Auto from Token Path: protocol/openid-connect/auth","title":"Keycloak settings"},{"location":"station_guide/central_ui/#create-a-realm-in-keycloak","text":"Create a realm - in this example: PHT_DEV Create a new client within this realm - in this example: pht-staging Set the access type to confidential and a root URL and the valid redirect URIs Copy your client secret and use it for the configuration in the UI The following two roles must be created in the identity provider","title":"Create a Realm in Keycloak"},{"location":"station_guide/central_ui/#registeringupdating-a-public-key","text":"Within the admin area (top left, next to Home), you need to select Auth -> Realms within the left navigation. You can see a list of stations. Choose the station you want and click on the blue \"List\"-Symbol. In Station the public key can be entered into the field PublicKey .","title":"Registering/Updating a public key"},{"location":"station_guide/central_ui/#updating-the-station-id","text":"Follow the steps 1 and 2 of \"Registering/Updating a public key\" On the same page you can find SecureID , which you can adapt.","title":"Updating the Station ID"},{"location":"station_guide/central_ui/#settingupdating-harbor-username-and-password","text":"Within the admin area (top left), you need select Realms within the left navigation. Select the Station you want to edit In Harbor the credentials, project name and path can be modified - webhooks for API communication can be tested.","title":"Setting/Updating harbor username and password"},{"location":"station_guide/central_ui/#review","text":"Before accepting a proposal or a train the requested data and the code contained in a train need to be reviewed. While removing network access and the built-in security features should be sufficient to prevent the transfer of data, the code still needs to be reviewed to prevent any unwanted behaviour.","title":"Review"},{"location":"station_guide/central_ui/#proposal","text":"Proposals are the top level organizational unit of the PHT system. Proposals describe the goal of an analysis, the requested data and an estimation of the potential risk of participation. When the description of the proposal meets the local requirements of your station, a user with the role of Station Authority can accept the proposal, otherwise the proposal is rejected (optionally with comments for improvement). Joining a proposal means that users of other stations also joined in the proposal can select your station as a participant in the trains they create for this proposal.","title":"Proposal"},{"location":"station_guide/central_ui/#train","text":"Trains contain analysis code that will be executed on the data requested in the proposal. The code is user submitted, so while the security protocol prevents the transfer of any unencrypted data via docker images and restricted network access, prevents direct transfer of any data, the code still needs to be reviewed in order to prevent any kind of malicious behaviour.","title":"Train"},{"location":"station_guide/installation/","text":"PHT Station This section will provide installation instructions for installing a PHT Station. It assumes that the station has been registered in the UI. Installation Visit the station repository to view the code (the installation instructions can also be found here). Requirements Docker and docker-compose need to be installed. For the default installation to work the ports 8080 and 5432 need to be available on localhost. Install with docker-compose Clone the repository: git clone https://github.com/PHT-Medic/station.git Navigate into the cloned project cd station and edit the .env file with your local configuration. The .env.tmpl file is a template file that can be used to generate a .env file with the correct environment keys. Attribute Explanation STATION_ID Chosen identifier of the station (match central UI configuration). You can find it as namespace STATION_PRIVATE_KEY_PATH Path to the private key on the local filesystem that should be mounted as a volume PRIVATE_KEY_PASSWORD If the private key is encrypted with a password, this password can be set using this variable AIRFLOW_USER Admin user to be created for the airflow instance AIRFLOW_PW Password for the airflow admin user HARBOR_URL Url of the central harbor instance HARBOR_USER Username to authenticate against harbor HARBOR_PW Password to authenticate against harbor STATION_DATA_DIR Absolute path of the directory where the station stores the input data for trains. This path is also used by the FHIR client to store the query results before passing them to the trains FHIR_ADDRESS (optional) Address of the default FHIR server connected to the station (this can also be configured per train) FHIR_USER (optional) Username to authenticate against the FHIR server using Basic Auth FHIR_PW (optional) Password for FHIR server Basic Auth FHIR_TOKEN (optional) Token to authenticate against the FHIR server using Bearer Token CLIENT_ID (optional) Identifier of client with permission to acces the FHIR server CLIENT_SECRET (optional) Secret of above client to authenticate against the provider OIDC_PROVIDER_URL (optional) Token url of Open ID connect provider (e.g. keycloak, that is configured for the FHIR server) FHIR_SERVER_TYPE (optional) Type of FHIR server (PHT FHIR client supports IBM, Hapi and Blaze FHIR servers) Create a volume for the station: docker volume create pg_station Build the images by running: docker-compose build First steps with running the station Run docker-compose up -d Check that the logs do not contain any startup errors with docker-compose logs -f Go to http://localhost:8080 nd check whether you can see the web interface of Apache Airflow Login to the airflow web interface with the previously set user credentials Troubleshooting/F.A.Q. I don't have a private key Generate a new key using open-ssl : openssl genrsa -out key.pem 2048 Generate the associated public key using: openssl rsa -in key.pem -outform PEM -pubout -out public.pem and then register this key in the UI. Windows installation If you are on a Windows Computer you need to change the line seperator to the Unix/macOS -style for the airflow directory. In Pycharm you can follow these steps: Select the airflow folder Click on File in the top-left corner Click on File Properties -> Line Separators -> LF - Unix and maxOS (\\n) Using pre-built images If there are issues while building the airflow container you can use our prebuilt images to run the airflow instance. Edit the airflow service in the docker-compose.yml file and replace the build command without prebuilt image: # ------------- ommitted ------------ services : airflow : # remove the build command build : './airflow' # replace with the image command image : ghcr.io/pht-medic/station-airflow:latest volumes : - /var/run/docker.sock:/var/run/docker.sock # ------------- ommitted ------------ Changing Airflow admin password/user Changing the Airflow admin password/user in the env file after the build is not directly possible. Either use Airflow UI to change the password or delete the airflow volume and rebuild after the change.","title":"Installation"},{"location":"station_guide/installation/#pht-station","text":"This section will provide installation instructions for installing a PHT Station. It assumes that the station has been registered in the UI.","title":"PHT Station"},{"location":"station_guide/installation/#installation","text":"Visit the station repository to view the code (the installation instructions can also be found here).","title":"Installation"},{"location":"station_guide/installation/#requirements","text":"Docker and docker-compose need to be installed. For the default installation to work the ports 8080 and 5432 need to be available on localhost.","title":"Requirements"},{"location":"station_guide/installation/#install-with-docker-compose","text":"Clone the repository: git clone https://github.com/PHT-Medic/station.git Navigate into the cloned project cd station and edit the .env file with your local configuration. The .env.tmpl file is a template file that can be used to generate a .env file with the correct environment keys. Attribute Explanation STATION_ID Chosen identifier of the station (match central UI configuration). You can find it as namespace STATION_PRIVATE_KEY_PATH Path to the private key on the local filesystem that should be mounted as a volume PRIVATE_KEY_PASSWORD If the private key is encrypted with a password, this password can be set using this variable AIRFLOW_USER Admin user to be created for the airflow instance AIRFLOW_PW Password for the airflow admin user HARBOR_URL Url of the central harbor instance HARBOR_USER Username to authenticate against harbor HARBOR_PW Password to authenticate against harbor STATION_DATA_DIR Absolute path of the directory where the station stores the input data for trains. This path is also used by the FHIR client to store the query results before passing them to the trains FHIR_ADDRESS (optional) Address of the default FHIR server connected to the station (this can also be configured per train) FHIR_USER (optional) Username to authenticate against the FHIR server using Basic Auth FHIR_PW (optional) Password for FHIR server Basic Auth FHIR_TOKEN (optional) Token to authenticate against the FHIR server using Bearer Token CLIENT_ID (optional) Identifier of client with permission to acces the FHIR server CLIENT_SECRET (optional) Secret of above client to authenticate against the provider OIDC_PROVIDER_URL (optional) Token url of Open ID connect provider (e.g. keycloak, that is configured for the FHIR server) FHIR_SERVER_TYPE (optional) Type of FHIR server (PHT FHIR client supports IBM, Hapi and Blaze FHIR servers) Create a volume for the station: docker volume create pg_station Build the images by running: docker-compose build","title":"Install with docker-compose"},{"location":"station_guide/installation/#first-steps-with-running-the-station","text":"Run docker-compose up -d Check that the logs do not contain any startup errors with docker-compose logs -f Go to http://localhost:8080 nd check whether you can see the web interface of Apache Airflow Login to the airflow web interface with the previously set user credentials","title":"First steps with running the station"},{"location":"station_guide/installation/#troubleshootingfaq","text":"","title":"Troubleshooting/F.A.Q."},{"location":"station_guide/installation/#i-dont-have-a-private-key","text":"Generate a new key using open-ssl : openssl genrsa -out key.pem 2048 Generate the associated public key using: openssl rsa -in key.pem -outform PEM -pubout -out public.pem and then register this key in the UI.","title":"I don't have a private key"},{"location":"station_guide/installation/#windows-installation","text":"If you are on a Windows Computer you need to change the line seperator to the Unix/macOS -style for the airflow directory. In Pycharm you can follow these steps: Select the airflow folder Click on File in the top-left corner Click on File Properties -> Line Separators -> LF - Unix and maxOS (\\n)","title":"Windows installation"},{"location":"station_guide/installation/#using-pre-built-images","text":"If there are issues while building the airflow container you can use our prebuilt images to run the airflow instance. Edit the airflow service in the docker-compose.yml file and replace the build command without prebuilt image: # ------------- ommitted ------------ services : airflow : # remove the build command build : './airflow' # replace with the image command image : ghcr.io/pht-medic/station-airflow:latest volumes : - /var/run/docker.sock:/var/run/docker.sock # ------------- ommitted ------------","title":"Using pre-built images"},{"location":"station_guide/installation/#changing-airflow-admin-passworduser","text":"Changing the Airflow admin password/user in the env file after the build is not directly possible. Either use Airflow UI to change the password or delete the airflow volume and rebuild after the change.","title":"Changing Airflow admin password/user"},{"location":"station_guide/station/","text":"Getting started with Airflow Trains and other station tasks are executed via airflow DAGs. The DAGs can be triggered via the airflow web interface, which is available under port :8080 on the station machine. The execution of the DAGs can also be monitored in the webinterface. Login The first time you access the webinterface you will be prompted to log in. Enter the credentials set in the .env file to login as admin. Or use the credentials that you have obtained from the station administrator. Triggering the test DAG To test the configuration of the station as defined in the .env file, trigger the DAG named test_station_configuration in the user interface. A DAG is triggered in the UI by clicking on the play button, where it can be started either with or without a json file containing additional configuration for the DAG run. Trigger the DAG without any additional configuration to check if the station is properly configured. A notification should appear in the UI that the DAG has been triggered. To monitor the execution click on the name of the DAG. You should see the individual tasks contained in the DAG as well as their status in the UI. If all tasks are marked as success, the station is properly configured and can connect to harbor as well as a FHIR server. Warning If you did not provide any FHIR_Server configurations in the .env-file, then this Trigger will fail, because this test will try to connect to the FHIR_server. All the nodes will be marked as red or orange except the \"get_dag_config\" Accessing logs The logs stored during the execution of a DAG can be accessed for each individual task by clicking the colored,squared/circled - indicator next to the name of the task. In the new pop-up window you can see in the top a list of options. There you can pick Log to view the Log of this task. If there are any errors stacktraces can be found in these logs, as well as any other output of the tasks (stdout, stderr) Running a train To execute a train that is available for your station, trigger the run_train DAG, with configuration options specifying the train image to be pulled from harbor and executed as well as additional environment variables or volumes. A template train configuration is displayed below. { \"repository\" : \"<HARBOR-REGISTRY>/<STATION_NAMESPACE>/<TRAIN-IMAGE>\" , \"tag\" : \"latest\" , \"env\" : { \"FHIR_SERVER_URL\" : \"<FHIR-ADDRESS>\" , \"FHIR_USER\" : \"<ID>\" , \"FHIR_PW\" : \"<PSW>\" } } Replace the placeholders with the values of the train image to execute, and other variables with the values corresponding to the stations configuration and paste it into the configuration form shown in the following image. Running a train with volume data Volume data (any data other than the data stored in the FHIR server) is made available to the train as read only volume mounts. This mount needs to specified in the configuration of the DAG when it is started. The path to which the volume must be mounted is specified in the train. { \"repository\" : \"<HARBOR-REGISTRY>/<STATION_NAMESPACE>/<TRAIN-ID>\" , \"tag\" : \"latest\" , \"volumes\" : { \"<Absolute path on station vm>\" : { \"bind\" : \"<Mount target in train container>\" , \"mode\" : \"ro\" } } }","title":"Station"},{"location":"station_guide/station/#getting-started-with-airflow","text":"Trains and other station tasks are executed via airflow DAGs. The DAGs can be triggered via the airflow web interface, which is available under port :8080 on the station machine. The execution of the DAGs can also be monitored in the webinterface.","title":"Getting started with Airflow"},{"location":"station_guide/station/#login","text":"The first time you access the webinterface you will be prompted to log in. Enter the credentials set in the .env file to login as admin. Or use the credentials that you have obtained from the station administrator.","title":"Login"},{"location":"station_guide/station/#triggering-the-test-dag","text":"To test the configuration of the station as defined in the .env file, trigger the DAG named test_station_configuration in the user interface. A DAG is triggered in the UI by clicking on the play button, where it can be started either with or without a json file containing additional configuration for the DAG run. Trigger the DAG without any additional configuration to check if the station is properly configured. A notification should appear in the UI that the DAG has been triggered. To monitor the execution click on the name of the DAG. You should see the individual tasks contained in the DAG as well as their status in the UI. If all tasks are marked as success, the station is properly configured and can connect to harbor as well as a FHIR server. Warning If you did not provide any FHIR_Server configurations in the .env-file, then this Trigger will fail, because this test will try to connect to the FHIR_server. All the nodes will be marked as red or orange except the \"get_dag_config\"","title":"Triggering the test DAG"},{"location":"station_guide/station/#accessing-logs","text":"The logs stored during the execution of a DAG can be accessed for each individual task by clicking the colored,squared/circled - indicator next to the name of the task. In the new pop-up window you can see in the top a list of options. There you can pick Log to view the Log of this task. If there are any errors stacktraces can be found in these logs, as well as any other output of the tasks (stdout, stderr)","title":"Accessing logs"},{"location":"station_guide/station/#running-a-train","text":"To execute a train that is available for your station, trigger the run_train DAG, with configuration options specifying the train image to be pulled from harbor and executed as well as additional environment variables or volumes. A template train configuration is displayed below. { \"repository\" : \"<HARBOR-REGISTRY>/<STATION_NAMESPACE>/<TRAIN-IMAGE>\" , \"tag\" : \"latest\" , \"env\" : { \"FHIR_SERVER_URL\" : \"<FHIR-ADDRESS>\" , \"FHIR_USER\" : \"<ID>\" , \"FHIR_PW\" : \"<PSW>\" } } Replace the placeholders with the values of the train image to execute, and other variables with the values corresponding to the stations configuration and paste it into the configuration form shown in the following image.","title":"Running a train"},{"location":"station_guide/station/#running-a-train-with-volume-data","text":"Volume data (any data other than the data stored in the FHIR server) is made available to the train as read only volume mounts. This mount needs to specified in the configuration of the DAG when it is started. The path to which the volume must be mounted is specified in the train. { \"repository\" : \"<HARBOR-REGISTRY>/<STATION_NAMESPACE>/<TRAIN-ID>\" , \"tag\" : \"latest\" , \"volumes\" : { \"<Absolute path on station vm>\" : { \"bind\" : \"<Mount target in train container>\" , \"mode\" : \"ro\" } } }","title":"Running a train with volume data"},{"location":"user_guide/desktop_app/","text":"PHT Desktop App The PHT Desktop App is the offline tool of the User Interface. It can sign hashes locally during the submission process of a train. After successful execution, it is used to decrypt downloaded results and key management. Installation Download the newest release for your operating system from github and install the software on your local machine. Create Keys This is an example to create an RSA-key-pair . The same steps are requiered for creating a homomorphic key-pair . Start the application. From the Homepage click on Settings on the left hand side. Click on the KeyPair -button of the RSA box. Specify the directory where the keys should be saved. Specify the filename of the private and the public key on the right side. Select a passphrase for your private key. (If you press enter, an empty passphrase will be used) Click on the Generate -button. Alternative approach Generate a new key using open-ssl : Open a command-line terminal Create and go to your specific folder where you want to store the new key-pair Type: openssl genrsa -passout pass:start123 -out private.pem 2048 for creating the private key Type: openssl rsa -in private.pem -passin pass:start123 -outform PEM -pubout -out public.pem for creating the assoziated public key. Sign Hash To perform the signature on a hash value it is necessary that the application knows your keypair (private and public key). (See Create Keys above). In the Menu click on Signature . In the Hash textfield you should paste the generated HashKey from step 2.6 in User Guide -> User interface . Click on Sign . Copy the signed hash from the Signature (read only) textfield and proceed step 2.6 in User Guide -> User interface . Decrypt results After executing a training in the UI, you can download the results to your local machine. Open the Desktop App -> Load your keys to the Desktop App via Settings -> Click on results on the menu. You will be directed to an overview where you can click on Select Result-File(.tar) button. Chose the downloaded results-file from the UI and press load. 3. A new view appears where you can chose which files you want to save. By clicking on the x -buttons, you can delete those files from the working space (you do not delete them from the results_file.tar, only a deletion from the Desktop App!). By clicking on the save -button you start downloading the remaining files. A new folder will be placed in the same folder where you have selected the result-File.tar.","title":"Desktop App (Offline Tool)"},{"location":"user_guide/desktop_app/#pht-desktop-app","text":"The PHT Desktop App is the offline tool of the User Interface. It can sign hashes locally during the submission process of a train. After successful execution, it is used to decrypt downloaded results and key management.","title":"PHT Desktop App"},{"location":"user_guide/desktop_app/#installation","text":"Download the newest release for your operating system from github and install the software on your local machine.","title":"Installation"},{"location":"user_guide/desktop_app/#create-keys","text":"This is an example to create an RSA-key-pair . The same steps are requiered for creating a homomorphic key-pair . Start the application. From the Homepage click on Settings on the left hand side. Click on the KeyPair -button of the RSA box. Specify the directory where the keys should be saved. Specify the filename of the private and the public key on the right side. Select a passphrase for your private key. (If you press enter, an empty passphrase will be used) Click on the Generate -button.","title":"Create Keys"},{"location":"user_guide/desktop_app/#alternative-approach","text":"Generate a new key using open-ssl : Open a command-line terminal Create and go to your specific folder where you want to store the new key-pair Type: openssl genrsa -passout pass:start123 -out private.pem 2048 for creating the private key Type: openssl rsa -in private.pem -passin pass:start123 -outform PEM -pubout -out public.pem for creating the assoziated public key.","title":"Alternative approach"},{"location":"user_guide/desktop_app/#sign-hash","text":"To perform the signature on a hash value it is necessary that the application knows your keypair (private and public key). (See Create Keys above). In the Menu click on Signature . In the Hash textfield you should paste the generated HashKey from step 2.6 in User Guide -> User interface . Click on Sign . Copy the signed hash from the Signature (read only) textfield and proceed step 2.6 in User Guide -> User interface .","title":"Sign Hash"},{"location":"user_guide/desktop_app/#decrypt-results","text":"After executing a training in the UI, you can download the results to your local machine. Open the Desktop App -> Load your keys to the Desktop App via Settings -> Click on results on the menu. You will be directed to an overview where you can click on Select Result-File(.tar) button. Chose the downloaded results-file from the UI and press load. 3. A new view appears where you can chose which files you want to save. By clicking on the x -buttons, you can delete those files from the working space (you do not delete them from the results_file.tar, only a deletion from the Desktop App!). By clicking on the save -button you start downloading the remaining files. A new folder will be placed in the same folder where you have selected the result-File.tar.","title":"Decrypt results"},{"location":"user_guide/fhir_query/","text":"Data in the PHT is accessed (or at least indexed) via a station-owned FHIR server. Users creating a train can specify the FHIR query to be executed either as a valid FHIR-API query string or by specifying the requested Resource(s) and the filter parameters in the query.json file created via the UI. For more information on available FHIR resources and the fields they contain, visit the FHIR Documentation . We assume connected FHIR servers fulfill the specifications defined in FHIR Release #4 (v4.0.1). Additionally, the query.json file contains specifications on how the response from the FHIR server should be stored and optionally parsed. The following example shows a JSON object defining a query for the Patient resource, the keys will be explained in the following sections. { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"gender\" , \"condition\" : \"male\" }, { \"variable\" : \"birthdate\" , \"condition\" : \"gt1980-08-12\" } ], \"has\" : [ { \"resource\" : \"Condition\" , \"property\" : \"code\" , \"params\" : [ \"E70.0\" , \"I20.0\" ] } ] }, \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"patients.json\" } } Writing a JSON Query To work properly the json object defined in the query.json file must contain the following fields: query defines the resource to query for and additional parameters to filter the results. data defines how the results of the query should be stored. The following sections will detail how to specify a valid FHIR query and define how the output will be stored. Defining the query The query key in the query.json file can either be a nested JSON object or a string. If it is a string this string is assumed to be a valid FHIR-API query string. In case of a nested JSON object, the object needs to contain the resource key which is the string identifier of the resource to query for. The other keys in the object are optional and can be used to define the filter parameters. Filter parameters Inside the query object the parameters key is used to define the filter parameters. The value of this key is a list of objects. Each object in the list defines a single filter parameter. The object defines the keys variable and condition . The variable key defines the name of the parameter, . notation can be used to access nested resources i.e. observation.code . The condition key defines the condition to be evaluated. The condition key can either a string or a list strings. Comparison operators such <= can be defined as prefixes are parsed according to the definitions of the FHIR API standards . Reverse Chaining Reverse chaining in FHIR is the process of selecting resources based on other resources that refer to them. For example, if a patient has a condition, the patient can then be selected based on the condition. The optional has key in the query defines the resource that refer to the resource defined in the resource key. It is defined as an object with the keys resource and property and params . Where the property is equivalent to the variable key in the filter parameters and the params is a list of strings that define the filter parameters. Specifying output The second required key in the query.json file is data . This key defines how the results of the query should be formatted and where the results should be stored. The value of this key is an object with the following keys: output_format : defines the format of the output. The value of this key is a string which can be either json or xml . filename : defines the name of the file where the results should be stored. Examples Minimal example - JSON This very minimal example shows how to define a query that simply gets all male patients and returns as output a csv file containing id, birthdate and gender for each patient matching the criteria (gender == male). { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"gender\" , \"condition\" : \"male\" } ] }, \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"patients.json\" } } Minimal Example - URL + JSON The following code block shows the definition of the same query as above but this time defined by a FHIR conform query string and returning the full resources returned by the server. { \"query\" : \"Patient?gender=male\" , \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"patients.json\" } } Advanced Example - JSON To define more complex queries, including resource chaining and additional variable has inside the query object of the query.json can be used to find resources based on other resources referring to them. The query defined in the example below extracts the same data as the minimal examples above but limits the returned patients based on Observations and Conditions that the patient is required to have. { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"gender\" , \"condition\" : \"male\" }, { \"variable\" : \"birthdate\" , \"condition\" : \"sa1980-08-12\" } ], \"has\" : [ { \"resource\" : \"Observation\" , \"property\" : \"code\" , \"params\" : [ \"I63.0\" , \"I63.1\" , \"I63.2\" , \"I63.3\" , \"I63.4\" , \"I63.5\" , \"I63.6\" , \"I63.7\" , \"I63.8\" , \"I63.9\" ] }, { \"resource\" : \"Condition\" , \"property\" : \"code\" , \"params\" : [ \"D70.0\" , \"D70.10\" , \"D70.11\" , \"D70.11\" , \"D70.12\" , \"D70.13\" , \"D70.14\" , \"D70.18\" , \"D70.19\" , \"D70.3\" , \"D70.5\" , \"D70.6\" , \"D70.7\" ] } ] }, \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"patients.json\" } } Advanced Example - URL + JSON The following code block shows the definition of the same query as above but this time defined by a FHIR conform query string and returning the full resources returned by the server. { \"query\" : \"Patient?gender=male&birthdate=sa1980-08-12&_has:Observation:patient:code=I63.0,I63.1,I63.2,I63.3,I63.4,I63.5,I63.6,I63.7,I63.8,I63.9&_has:Condition:patient:code=D70.0,D70.10,D70.11,D70.11,D70.12,D70.13,D70.14,D70.18,D70.19,D70.3,D70.5,D70.6,D70.7\" , \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"patients.json\" } }","title":"FHIR Query"},{"location":"user_guide/fhir_query/#writing-a-json-query","text":"To work properly the json object defined in the query.json file must contain the following fields: query defines the resource to query for and additional parameters to filter the results. data defines how the results of the query should be stored. The following sections will detail how to specify a valid FHIR query and define how the output will be stored.","title":"Writing a JSON Query"},{"location":"user_guide/fhir_query/#defining-the-query","text":"The query key in the query.json file can either be a nested JSON object or a string. If it is a string this string is assumed to be a valid FHIR-API query string. In case of a nested JSON object, the object needs to contain the resource key which is the string identifier of the resource to query for. The other keys in the object are optional and can be used to define the filter parameters.","title":"Defining the query"},{"location":"user_guide/fhir_query/#filter-parameters","text":"Inside the query object the parameters key is used to define the filter parameters. The value of this key is a list of objects. Each object in the list defines a single filter parameter. The object defines the keys variable and condition . The variable key defines the name of the parameter, . notation can be used to access nested resources i.e. observation.code . The condition key defines the condition to be evaluated. The condition key can either a string or a list strings. Comparison operators such <= can be defined as prefixes are parsed according to the definitions of the FHIR API standards .","title":"Filter parameters"},{"location":"user_guide/fhir_query/#reverse-chaining","text":"Reverse chaining in FHIR is the process of selecting resources based on other resources that refer to them. For example, if a patient has a condition, the patient can then be selected based on the condition. The optional has key in the query defines the resource that refer to the resource defined in the resource key. It is defined as an object with the keys resource and property and params . Where the property is equivalent to the variable key in the filter parameters and the params is a list of strings that define the filter parameters.","title":"Reverse Chaining"},{"location":"user_guide/fhir_query/#specifying-output","text":"The second required key in the query.json file is data . This key defines how the results of the query should be formatted and where the results should be stored. The value of this key is an object with the following keys: output_format : defines the format of the output. The value of this key is a string which can be either json or xml . filename : defines the name of the file where the results should be stored.","title":"Specifying output"},{"location":"user_guide/fhir_query/#examples","text":"","title":"Examples"},{"location":"user_guide/fhir_query/#minimal-example-json","text":"This very minimal example shows how to define a query that simply gets all male patients and returns as output a csv file containing id, birthdate and gender for each patient matching the criteria (gender == male). { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"gender\" , \"condition\" : \"male\" } ] }, \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"patients.json\" } }","title":"Minimal example - JSON"},{"location":"user_guide/fhir_query/#minimal-example-url-json","text":"The following code block shows the definition of the same query as above but this time defined by a FHIR conform query string and returning the full resources returned by the server. { \"query\" : \"Patient?gender=male\" , \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"patients.json\" } }","title":"Minimal Example - URL + JSON"},{"location":"user_guide/fhir_query/#advanced-example-json","text":"To define more complex queries, including resource chaining and additional variable has inside the query object of the query.json can be used to find resources based on other resources referring to them. The query defined in the example below extracts the same data as the minimal examples above but limits the returned patients based on Observations and Conditions that the patient is required to have. { \"query\" : { \"resource\" : \"Patient\" , \"parameters\" : [ { \"variable\" : \"gender\" , \"condition\" : \"male\" }, { \"variable\" : \"birthdate\" , \"condition\" : \"sa1980-08-12\" } ], \"has\" : [ { \"resource\" : \"Observation\" , \"property\" : \"code\" , \"params\" : [ \"I63.0\" , \"I63.1\" , \"I63.2\" , \"I63.3\" , \"I63.4\" , \"I63.5\" , \"I63.6\" , \"I63.7\" , \"I63.8\" , \"I63.9\" ] }, { \"resource\" : \"Condition\" , \"property\" : \"code\" , \"params\" : [ \"D70.0\" , \"D70.10\" , \"D70.11\" , \"D70.11\" , \"D70.12\" , \"D70.13\" , \"D70.14\" , \"D70.18\" , \"D70.19\" , \"D70.3\" , \"D70.5\" , \"D70.6\" , \"D70.7\" ] } ] }, \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"patients.json\" } }","title":"Advanced Example - JSON"},{"location":"user_guide/fhir_query/#advanced-example-url-json","text":"The following code block shows the definition of the same query as above but this time defined by a FHIR conform query string and returning the full resources returned by the server. { \"query\" : \"Patient?gender=male&birthdate=sa1980-08-12&_has:Observation:patient:code=I63.0,I63.1,I63.2,I63.3,I63.4,I63.5,I63.6,I63.7,I63.8,I63.9&_has:Condition:patient:code=D70.0,D70.10,D70.11,D70.11,D70.12,D70.13,D70.14,D70.18,D70.19,D70.3,D70.5,D70.6,D70.7\" , \"data\" : { \"output_format\" : \"json\" , \"filename\" : \"patients.json\" } }","title":"Advanced Example - URL + JSON"},{"location":"user_guide/trains/","text":"PHT Trains This section will provide explanations and example for writing code and queries for PHT trains, it does not cover the organizational aspects (such as what stations participate etc.) but focuses on how to write the code that will be executed as a train and how to define queries. Information on how to build trains and actually send them on their way can be found in the user guide for the UI . This example can be used as entrypoint.py , which is namely reference in this documentation. Defining Trains Example Train Calculate average age based on a fhir query The query to be used in this train is the JSON version of the minimal example found in the next section. What this train will do ist calculate the average age of patients matching the query across multiple stations. The stations will pass the query results to the train as volumes and also set the environment variable TRAIN_DATA_PATH inside the train container, which is used by the train to load the passed json file. import pandas as pd import os import json import datetime RESULTS_PATH = \"/opt/pht_results/average_age.json\" def load_previous_data ( path ): if os . path . exists ( path ): with open ( path , \"r\" ) as f : average_age_dict = json . load ( f ) return average_age_dict else : return None def age_from_dob ( dob ): today = datetime . date . today () return today . year - dob . year - (( today . month , today . day ) < ( dob . month , dob . day )) def parse_fhir_response ( data_path ) -> pd . DataFrame : \"\"\" Load and parse provided FHIR resources to a pandas dataframe :return: \"\"\" with open ( data_path , \"r\" ) as f : results = json . load ( f ) parsed_resources = [] for patient in results [ \"entry\" ]: resource = patient [ \"resource\" ] parsed_resources . append ( parse_resource ( resource )) df = pd . DataFrame ( parsed_resources ) return df def parse_resource ( resource ): \"\"\" Parse a FHIR resource returned from a FHIR server in a desired format :param resource: :return: dictionary of parsed resource \"\"\" sequence_dict = { \"givenName\" : resource [ 'name' ][ 0 ][ 'given' ], \"familyName\" : resource [ 'name' ][ 0 ][ 'family' ], \"birthDate\" : resource [ \"birthDate\" ], \"gender\" : resource [ \"gender\" ] } return sequence_dict def calculate_new_average ( average_age_dict , data_path , results_path ): # load the data and ensure that birthdate is a datetime column data = parse_fhir_response ( data_path ) data [ \"birthDate\" ] = pd . to_datetime ( data [ \"birthDate\" ]) ages = data [ \"birthDate\" ] . apply ( lambda x : age_from_dob ( x )) local_average = ages . mean () # previous results exist load them otherwise create a new dictionary containing the results if average_age_dict : prev_average = average_age_dict [ \"average_age\" ] new_average = ( prev_average + local_average ) / 2 if prev_average else local_average average_age_dict [ \"average_age\" ] = new_average else : new_average = local_average average_age_dict = { \"average_age\" : new_average } print ( average_age_dict ) # store the updated results with open ( results_path , \"w\" ) as f : json . dump ( average_age_dict , fp = f , indent = 2 ) def main (): data_path = os . getenv ( \"TRAIN_DATA_PATH\" , \"/opt/train_data/patients.json\" ) print ( f \"Loading data at { data_path } \" ) prev_results = load_previous_data ( RESULTS_PATH ) calculate_new_average ( prev_results , data_path , RESULTS_PATH ) if __name__ == '__main__' : main ()","title":"Trains"},{"location":"user_guide/trains/#pht-trains","text":"This section will provide explanations and example for writing code and queries for PHT trains, it does not cover the organizational aspects (such as what stations participate etc.) but focuses on how to write the code that will be executed as a train and how to define queries. Information on how to build trains and actually send them on their way can be found in the user guide for the UI . This example can be used as entrypoint.py , which is namely reference in this documentation.","title":"PHT Trains"},{"location":"user_guide/trains/#defining-trains","text":"","title":"Defining Trains"},{"location":"user_guide/trains/#example-train","text":"","title":"Example Train"},{"location":"user_guide/trains/#calculate-average-age-based-on-a-fhir-query","text":"The query to be used in this train is the JSON version of the minimal example found in the next section. What this train will do ist calculate the average age of patients matching the query across multiple stations. The stations will pass the query results to the train as volumes and also set the environment variable TRAIN_DATA_PATH inside the train container, which is used by the train to load the passed json file. import pandas as pd import os import json import datetime RESULTS_PATH = \"/opt/pht_results/average_age.json\" def load_previous_data ( path ): if os . path . exists ( path ): with open ( path , \"r\" ) as f : average_age_dict = json . load ( f ) return average_age_dict else : return None def age_from_dob ( dob ): today = datetime . date . today () return today . year - dob . year - (( today . month , today . day ) < ( dob . month , dob . day )) def parse_fhir_response ( data_path ) -> pd . DataFrame : \"\"\" Load and parse provided FHIR resources to a pandas dataframe :return: \"\"\" with open ( data_path , \"r\" ) as f : results = json . load ( f ) parsed_resources = [] for patient in results [ \"entry\" ]: resource = patient [ \"resource\" ] parsed_resources . append ( parse_resource ( resource )) df = pd . DataFrame ( parsed_resources ) return df def parse_resource ( resource ): \"\"\" Parse a FHIR resource returned from a FHIR server in a desired format :param resource: :return: dictionary of parsed resource \"\"\" sequence_dict = { \"givenName\" : resource [ 'name' ][ 0 ][ 'given' ], \"familyName\" : resource [ 'name' ][ 0 ][ 'family' ], \"birthDate\" : resource [ \"birthDate\" ], \"gender\" : resource [ \"gender\" ] } return sequence_dict def calculate_new_average ( average_age_dict , data_path , results_path ): # load the data and ensure that birthdate is a datetime column data = parse_fhir_response ( data_path ) data [ \"birthDate\" ] = pd . to_datetime ( data [ \"birthDate\" ]) ages = data [ \"birthDate\" ] . apply ( lambda x : age_from_dob ( x )) local_average = ages . mean () # previous results exist load them otherwise create a new dictionary containing the results if average_age_dict : prev_average = average_age_dict [ \"average_age\" ] new_average = ( prev_average + local_average ) / 2 if prev_average else local_average average_age_dict [ \"average_age\" ] = new_average else : new_average = local_average average_age_dict = { \"average_age\" : new_average } print ( average_age_dict ) # store the updated results with open ( results_path , \"w\" ) as f : json . dump ( average_age_dict , fp = f , indent = 2 ) def main (): data_path = os . getenv ( \"TRAIN_DATA_PATH\" , \"/opt/train_data/patients.json\" ) print ( f \"Loading data at { data_path } \" ) prev_results = load_previous_data ( RESULTS_PATH ) calculate_new_average ( prev_results , data_path , RESULTS_PATH ) if __name__ == '__main__' : main ()","title":"Calculate average age based on a fhir query"},{"location":"user_guide/user_interface/","text":"User Interface The User Interface (UI) https://pht-medic.medizin.uni-tuebingen.de is the central control interface to interact with the PHT. Its main tasks are the administration of stations and train proposals but also the submission of analysis-trains and consequently receiving encrypted results. User Account Configuration Registering/Updating a public key After signing in for the first time you should register a public key in the UI (Vault). In the Home section press Settings in the menu on the left-hand side and then press Secrets . You can define the ... ... key type : You can choose between an RSA-key and a Paillier-key ... key name : The preferred name for this specific key Furthermore, you do have two options for loading the key into the system: Load the key via the file path (through the Browse option) Copy and paste the whole key into the Content -section. On the right sight, you will then find each already stored keys with specific name as list below the Overview and the search bar (where you can filter after a specific key in the list) Proposals A Proposal is an organizational unit in the PHT, which represents the collaboration between different participants in regard to a specific research or analysis project. It contains an initial risk assessment as well as a high level description of the requested data. In the Home section press Proposals in the menu on the left-hand side. At first, you will lead to the outgoing -proposals section, where you can see a list of all the proposals created by this station. Via the searchbar you can filter after the name. You have the option to adjust the already existing proposals via the List -icon or to delete the proposal via the bin -icon. Furthermore, you can see, who exactly created that proposal. Moreover, you have the option to switch to the incoming section or to create a new proposal on the left side between the menu and the overview-list. Creating a new Proposal After pressing the Create -button, it will take you to a new form. Here you can define principal aspects of you train. You can define ... ... a title of the proposal. ... the group where you can choose from cord, python, leuko-expert and R ... Additionally you can select the Image such as base (for cord | leuko-expert | python), ml (for python | r) and conda , pytorch , tensorflow (for python). ... the risk level and specifies it by context in the risk comment: Low | Mid | High . ... to which of the known stations you want to send this proposal. (You can choose multiple stations by clicking on the green + -icon.) ... some Data/Parameters information, which will be necessary for the training algorithm in the Data/Parameter - text block. After clicking on the create-button the proposal will be sent to all the selected stations, such each side can approve/reject the analysis. Definition of Risk A train is working on specific data from the different station but data can be quite differentiable depending on combinations of all data. Private data is really sensitive and needs to be handled accordingly. So we give a Risk, so each station can have a clue about what kind of data will be used during the stopover of the train. For this we have three stages: Low risk ( green ): The train won't use any personal related data, such as calculation about all Loinc-Codes of Observation-Resources in a FHIR-Server. Mid risk ( yellow ): The train will use only one or quite few personal information of a patient such as the gender or the age. One param will not be harmful at all, but should still be mentioned when used during the process. High ( red ): The train in general will perform some calculations / analysis on private data where it can be possible that private information can be figured out about a single person. This can occur when the calculations will be performed on only a few participants with many private data about them. Overall this should not be an issue, when the FHIR-Servers provide enough privacy preserving measurements such as pseudonymization or anonymization. Accepting/Rejecting an incoming proposal Within the incoming section of each station, a station authority can independently decide to comment, approve or reject a study proposal for analysis. In order to do such, click on the list -icon on the right side of the corresponding proposal and select the preferred action. Train submission 1. Add user key If no public key has been registered yet follow the instructions in user account configuration section. 2. Create a new train In the Home section you can choose Trains in the menu on the left-hand side. You will lead to the Outgoing page where you can switch to the creation form via the Create button inbetween the menu and the overview-list. 2.1. Define pre-parameters of the new train On this page you can define: an optional name for the given train. which type of train you want to create. There are two options: Discovery : A discovery train can be used to get to know about the availability of data at the targeted stations. Analysis : An analyse train should be created on base of the knowledge achieved during the discovery phase to which proposal the train is associated. Only one proposal can be selected. Click on create to continue. 2.2. Define MasterImage and choose Stations At this point the MasterImage settings are taking from the chosen proposal but can still be changed. Additionally, you can select those stations you want the train to be sent to. The order you selected the stations will define the path the train will pursue. Click on Next to continue. 2.3. Check the Security Settings You need to select one of your registered RSA public keys for encrypting the train. Additionally, you can add a Paillier-key to be used for homomorphic encryption. Click on Next to continue. 2.4. Load Code to the train In the file-section of the train submission you can upload the files containing your code, which the train will execute while visiting the different stations. You can decide whether you want to upload only one single file or a whole directory of files. Depending on you decision you need to mark or unmark the Directory mode -switch. After you have selected the file or directory via the browse-button you can find all the files listed below. Depending on the folder, you may not wish to upload each file, so it is possible to delete some files at this point. After uploading the files to the train you need to select one of the files as entrypoint. It is not name-depending as you can see in the picture below. You can select the specific file by clicking on the green-button. The chosen file will be displayed in the black textfield. We have chosen the stuff_1.py as entrypoint for showing you, that it is not necessary to name one of your files \"entrypoint\". By clicking on the yellow X -button you deselect this file. Additionally, you can delete some files as well at this point. Click on Next to continue. 2.5. Add a FHIR Query In the Extra -section of the train submission you can add your valid FHIR Query to the train. It can be either the option with parameters or as URL version. You can find more information about the query in this documentation under the section User Guide -> FHIR Query Here we used an example query from the FHIR Query documentation. 2.6. Create Hash and Signature One of the last steps it is to create a hash of the train started by this station. For this you need to generate the hash-value. (This could take some time) After the hash value was generated, copy it and perform the signature on this with your private key. For this action you need to download and install the Offline Tool. How this signature is performed you can read it in this documentation under the section User Guide -> Desktop App (Offline Tool) The final signature from the Offline App you need to the textfield Signed Hash . Click on Next to finish the configuration step. 3. Start the train At this point the train is ready to be led loose on the track. You can start the train by firstly build the whole train together (by clicking on the green start -button next to Build ). After a successful build train you can Run the train, which starts visiting the stations and perform your code. Each station needs to start the code manually via the Airflow-Control of the station. You can find more information here: Station After running through all station, you can click on the Download -button on point 4.Result . To decrypt the results, you need the Desktop App (Offline Tool) again.","title":"User Interface"},{"location":"user_guide/user_interface/#user-interface","text":"The User Interface (UI) https://pht-medic.medizin.uni-tuebingen.de is the central control interface to interact with the PHT. Its main tasks are the administration of stations and train proposals but also the submission of analysis-trains and consequently receiving encrypted results.","title":"User Interface"},{"location":"user_guide/user_interface/#user-account-configuration","text":"","title":"User Account Configuration"},{"location":"user_guide/user_interface/#registeringupdating-a-public-key","text":"After signing in for the first time you should register a public key in the UI (Vault). In the Home section press Settings in the menu on the left-hand side and then press Secrets . You can define the ... ... key type : You can choose between an RSA-key and a Paillier-key ... key name : The preferred name for this specific key Furthermore, you do have two options for loading the key into the system: Load the key via the file path (through the Browse option) Copy and paste the whole key into the Content -section. On the right sight, you will then find each already stored keys with specific name as list below the Overview and the search bar (where you can filter after a specific key in the list)","title":"Registering/Updating a public key"},{"location":"user_guide/user_interface/#proposals","text":"A Proposal is an organizational unit in the PHT, which represents the collaboration between different participants in regard to a specific research or analysis project. It contains an initial risk assessment as well as a high level description of the requested data. In the Home section press Proposals in the menu on the left-hand side. At first, you will lead to the outgoing -proposals section, where you can see a list of all the proposals created by this station. Via the searchbar you can filter after the name. You have the option to adjust the already existing proposals via the List -icon or to delete the proposal via the bin -icon. Furthermore, you can see, who exactly created that proposal. Moreover, you have the option to switch to the incoming section or to create a new proposal on the left side between the menu and the overview-list.","title":"Proposals"},{"location":"user_guide/user_interface/#creating-a-new-proposal","text":"After pressing the Create -button, it will take you to a new form. Here you can define principal aspects of you train. You can define ... ... a title of the proposal. ... the group where you can choose from cord, python, leuko-expert and R ... Additionally you can select the Image such as base (for cord | leuko-expert | python), ml (for python | r) and conda , pytorch , tensorflow (for python). ... the risk level and specifies it by context in the risk comment: Low | Mid | High . ... to which of the known stations you want to send this proposal. (You can choose multiple stations by clicking on the green + -icon.) ... some Data/Parameters information, which will be necessary for the training algorithm in the Data/Parameter - text block. After clicking on the create-button the proposal will be sent to all the selected stations, such each side can approve/reject the analysis.","title":"Creating a new Proposal"},{"location":"user_guide/user_interface/#definition-of-risk","text":"A train is working on specific data from the different station but data can be quite differentiable depending on combinations of all data. Private data is really sensitive and needs to be handled accordingly. So we give a Risk, so each station can have a clue about what kind of data will be used during the stopover of the train. For this we have three stages: Low risk ( green ): The train won't use any personal related data, such as calculation about all Loinc-Codes of Observation-Resources in a FHIR-Server. Mid risk ( yellow ): The train will use only one or quite few personal information of a patient such as the gender or the age. One param will not be harmful at all, but should still be mentioned when used during the process. High ( red ): The train in general will perform some calculations / analysis on private data where it can be possible that private information can be figured out about a single person. This can occur when the calculations will be performed on only a few participants with many private data about them. Overall this should not be an issue, when the FHIR-Servers provide enough privacy preserving measurements such as pseudonymization or anonymization.","title":"Definition of Risk"},{"location":"user_guide/user_interface/#acceptingrejecting-an-incoming-proposal","text":"Within the incoming section of each station, a station authority can independently decide to comment, approve or reject a study proposal for analysis. In order to do such, click on the list -icon on the right side of the corresponding proposal and select the preferred action.","title":"Accepting/Rejecting an incoming proposal"},{"location":"user_guide/user_interface/#train-submission","text":"","title":"Train submission"},{"location":"user_guide/user_interface/#1-add-user-key","text":"If no public key has been registered yet follow the instructions in user account configuration section.","title":"1. Add user key"},{"location":"user_guide/user_interface/#2-create-a-new-train","text":"In the Home section you can choose Trains in the menu on the left-hand side. You will lead to the Outgoing page where you can switch to the creation form via the Create button inbetween the menu and the overview-list.","title":"2. Create a new train"},{"location":"user_guide/user_interface/#21-define-pre-parameters-of-the-new-train","text":"On this page you can define: an optional name for the given train. which type of train you want to create. There are two options: Discovery : A discovery train can be used to get to know about the availability of data at the targeted stations. Analysis : An analyse train should be created on base of the knowledge achieved during the discovery phase to which proposal the train is associated. Only one proposal can be selected. Click on create to continue.","title":"2.1. Define pre-parameters of the new train"},{"location":"user_guide/user_interface/#22-define-masterimage-and-choose-stations","text":"At this point the MasterImage settings are taking from the chosen proposal but can still be changed. Additionally, you can select those stations you want the train to be sent to. The order you selected the stations will define the path the train will pursue. Click on Next to continue.","title":"2.2. Define MasterImage and choose Stations"},{"location":"user_guide/user_interface/#23-check-the-security-settings","text":"You need to select one of your registered RSA public keys for encrypting the train. Additionally, you can add a Paillier-key to be used for homomorphic encryption. Click on Next to continue.","title":"2.3. Check the Security Settings"},{"location":"user_guide/user_interface/#24-load-code-to-the-train","text":"In the file-section of the train submission you can upload the files containing your code, which the train will execute while visiting the different stations. You can decide whether you want to upload only one single file or a whole directory of files. Depending on you decision you need to mark or unmark the Directory mode -switch. After you have selected the file or directory via the browse-button you can find all the files listed below. Depending on the folder, you may not wish to upload each file, so it is possible to delete some files at this point. After uploading the files to the train you need to select one of the files as entrypoint. It is not name-depending as you can see in the picture below. You can select the specific file by clicking on the green-button. The chosen file will be displayed in the black textfield. We have chosen the stuff_1.py as entrypoint for showing you, that it is not necessary to name one of your files \"entrypoint\". By clicking on the yellow X -button you deselect this file. Additionally, you can delete some files as well at this point. Click on Next to continue.","title":"2.4. Load Code to the train"},{"location":"user_guide/user_interface/#25-add-a-fhir-query","text":"In the Extra -section of the train submission you can add your valid FHIR Query to the train. It can be either the option with parameters or as URL version. You can find more information about the query in this documentation under the section User Guide -> FHIR Query Here we used an example query from the FHIR Query documentation.","title":"2.5. Add a FHIR Query"},{"location":"user_guide/user_interface/#26-create-hash-and-signature","text":"One of the last steps it is to create a hash of the train started by this station. For this you need to generate the hash-value. (This could take some time) After the hash value was generated, copy it and perform the signature on this with your private key. For this action you need to download and install the Offline Tool. How this signature is performed you can read it in this documentation under the section User Guide -> Desktop App (Offline Tool) The final signature from the Offline App you need to the textfield Signed Hash . Click on Next to finish the configuration step.","title":"2.6. Create Hash and Signature"},{"location":"user_guide/user_interface/#3-start-the-train","text":"At this point the train is ready to be led loose on the track. You can start the train by firstly build the whole train together (by clicking on the green start -button next to Build ). After a successful build train you can Run the train, which starts visiting the stations and perform your code. Each station needs to start the code manually via the Airflow-Control of the station. You can find more information here: Station After running through all station, you can click on the Download -button on point 4.Result . To decrypt the results, you need the Desktop App (Offline Tool) again.","title":"3. Start the train"}]}